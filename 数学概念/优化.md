# 优化

## 常见的优化算法[详情参考](https://wenku.baidu.com/view/963be8e09dc3d5bbfd0a79563c1ec5da50e2d635.html?_wkts_=1669014966182&bdQuery=H+%3D+JTJ)
- 求解非线性最小二乘问题
$$
\min_{x}  F(x) = \frac{1}{2}\left \|  f(x)\right \| ^2_2
$$
使用泰勒展开进行近似，求解变化量$\Delta x$
$$
F(x_k+\Delta x_k) \approx F(x_k) + J^T(x_k)\Delta x_k + \frac{1}{2}\Delta x_k^TH(x_k)\Delta x_k
$$
### 最速下降法
- 梯度方向是上升方向，所以沿着负梯度方向$-J$更新$x$,可以使$F(x)$逐步获得最小值。更新的步长为$-\lambda$
- $\Delta x=-\lambda J$
- 是下降算法。容易出现锯齿现象，增加迭代的次数
### 牛顿法
- 二阶泰勒展开的数值最小，一般是对$\Delta x$求导导数为0的极值点。
- $J+H\Delta x = 0$
- 是下降算法。需要计算H矩阵，计算量大
### 高斯牛顿法
- 思路使用$f(x)$的雅可比矩阵$J(x)J^T(x)$近似$H$矩阵。$f(x +\Delta x)  = f(x) + J(x)^T \Delta x$。带入计算后使得导数为0可得到：
- $J(x)J^T(x) \Delta x = - J(x)f(x) \Rightarrow H(x)\Delta x = g(x)$
- 避免了计算$H$导致的计算量过大的问题,使用$J(x)J^T(x)$近似的$H(x)$半正定可能出现奇异病态；近似的$H(x)$只在$x$附近效果不错，可能出现求解得到的$\Delta x$的步长过大，局部的近似不准确的问题。
### LM优化算法
- 考虑到高斯牛顿法近似不准确，给定一个近似的信赖区间半径$\mu$，$||D \Delta x||^2 \le μ$，$D$为系数矩阵。根据$\rho = \frac{f(x + \Delta x)-f(x)}{J^T(x)\Delta x}$指标判断$\mu$的好坏，$\rho$约接近1近似效果好。$\rho$大于一定值可以增加$\mu$半径，反之亦然。
- 通过拉格朗日乘子法将收敛区间融合到目标函数中。求解无约束问题$\mathcal{L}(\Delta x , \lambda) = \frac{1}{2}\left \| f(x) +J^T\Delta x \right \|^2  +\frac{\lambda}{2}(\left \| D\Delta x \right \|^2-\mu )$，化简得到：$(H(x) + \lambda D^TD) \Delta x= g(x)$
- 相比于高斯牛顿法多了$\lambda D^TD$，可以将$ D^TD$近似为单位矩阵 $I$进行简化,$\lambda$比较小时，近似于高斯牛顿法；。$\lambda$比较大的时候，$\lambda I$占主要地位，近似于最速度下降法。

## 滑窗优化(参考VINS)
### 滑窗中的边缘化生成先验
- 滑窗优化中需要维持固定的帧数的关键帧，当滑窗中的帧数已经达到最大，又有新的关键帧需要添加时。需要先对要剔除的关键帧进行边缘化，使得剔除的关键帧留下先验约束部分，其他关键帧保留不变。
- 边缘化会有fillin操作，这会导致矩阵H不在具有稀疏性。
### 滑窗中的合并新旧信息
- 边缘化留下的先验残差，先验残差的雅可比矩阵后续无法更新，则其线性化点固定在边缘化之前的状态量处。
- 新的残差约束到的状态量，新的残差的状态量雅可比矩阵的线性化点会在优化过程中根据状态量位置不断变化。
- 当先验残差与信增残差约束相同的状态量，合并时，导致同一个状态量的先验残差的雅可比的线性化点与新增的残差的雅可比不一致。对同一个状态量在不同的位置进行线性化，会引入人为的错误观测约束，这可能会导致系统崩溃。
- 通过FEJ算法解决这个问题。
#### FEJ算法 First Estimated Jacobian
- VINS中没有使用FEJ算法
- emmmm之后再看[这个吧](https://zhuanlan.zhihu.com/p/304889273)

## 优化求解中的 稀疏性 和 边缘化 Marginalizatio (Schur消元)
### 稀疏性
- 定义：通常来说求解$H \Delta x = g$时候，$H = \sum J_{i,j}TJ_{i,j}$，如果按照先相机，后观测点的顺序，不同的两个观测点对应位置的矩阵块是为0的，这个就是一般所说H矩阵的稀疏性。
- 利用稀疏性可以加速矩阵计算，这个假设加速计算过程称为边缘化(Marginalization)或者Schur消元。
### 边缘化 Marginalizatio (Schur消元)
- $H \Delta x = g$ 可以写成分块的形式 $\begin{bmatrix}B&E \\E^T&C\end{bmatrix} \begin{bmatrix}\Delta x_c\\\Delta x_p\end{bmatrix} =
\begin{bmatrix}v\\w\end{bmatrix}$
- Schur消元：消除右上角的矩阵$E$，方程变为$\begin{bmatrix}B - EC^{-1}E^T&0 \\E^T&C\end{bmatrix} \begin{bmatrix}\Delta x_c\\\Delta x_p\end{bmatrix} =
\begin{bmatrix}v -EC^{-1}w \\w\end{bmatrix}$
- 求解：1.求解第一行$\begin{bmatrix}B - EC^{-1}E^T&0 \end{bmatrix} \begin{bmatrix}\Delta x_c\end{bmatrix} =
\begin{bmatrix}v -EC^{-1}w \end{bmatrix}$得到相机状态$\Delta x_c$。2.将$\Delta x_c$带入，通过第二行求解$\Delta x_p = C^{-1}\left (w -E^T \Delta x_c \right ) $
- 边缘化 Marginalizatio：是因为上说求解过程，可以看做是先固定$\Delta x_p$求解$\Delta x_c$，从概率上看是求解$P(x_c,x_p) = P(x_c|x_p)P(x_p)$，就是把$x_p$边缘化，将$\Delta  x_p$看做已知的先验提供约束来求解$\Delta x_c$。

## 优化库
### g2o
#### 优化器
#### 求解器
#### 顶点 优化变量
#### 边 误差
##### 信息矩阵
- 可以看做是该误差项在整体优化中的权重。数值上等于误差的协方差的逆$\Sigma_{error} ^{-1}$，$error =  f(x,y,z)$ ,其中$x$是待优化变量，$y，z$是其他已知的变量,则$\delta error = f(x,y,z) - f(x,y+\delta y,z+\delta z)$,协方差$\Sigma_{error} = J_{\delta y}\Sigma_{\delta y}J_{\delta y}^T + J_{\delta z}\Sigma_{\delta z}J_{\delta z}^T$ 
##### 鲁棒核函数
- $b(2|x|-b),x>b$
### ceres
